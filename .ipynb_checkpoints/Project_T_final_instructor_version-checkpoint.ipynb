{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project T Final: PCA and CCA\n",
    "\n",
    "By Jai Bansal, Abhinav Gopal, Grace Kull, William McEachen, Shrey Vasavada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below only once per session. The utils.py file contains some black box functions which will be used later in this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ./utils.py utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will be looking at a real dataset of baseball players, and using the information to predict their salaries. Some of the information in this dataset about the players includes their names, ids, positions, years played, and their batting statistics. \n",
    "\n",
    "First, load the csv file to see all the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv(\"baseball_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the initial obsevation of the data, it is clear that the types of data needed to predict salaries will be numerical, or categorical. Additionally, rows with no salary information will have no use to us. So we'll start the data cleaning process by dropping columns that don't have categorical or numerical data, and dropping rows with no salary information. The columns being dropped are 'id', 'yearid','teamid','lgid','namefirst','namelast', and 'g_batting'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = baseball.drop(columns = ['id', 'yearid','teamid','lgid','namefirst','namelast', 'g_batting'])\n",
    "data = data[data['salary'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now start one-hot encoding our position data. Because there are several different positions, where each one can have an impact on a player's salary, it is important for us to take that data into account, even though it's not numerical. We will create a new column for each different kind of position and for each row, the value of that column will be 1 if the player is in that position, and 0 if the player is not. Fill out the cell below to implement one-hot encoding. Remember to drop the original 'pos' column from the dataset when the one-hot encoding is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for each of the different positions\n",
    "\n",
    "# Solution #\n",
    "positions = np.unique(data['pos'])\n",
    "temp_array = np.array(data['pos'])\n",
    "for position in positions:\n",
    "    indicator = np.zeros(len(data['pos']))\n",
    "    for j in range(len(temp_array)):\n",
    "        if temp_array[j] == position:\n",
    "            indicator[j] = 1\n",
    "    data[position] = indicator\n",
    "# End solution #\n",
    "\n",
    "data_one_hot = data.drop(columns = ['pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, replace all NaN values with 0.0, as all data is numerical at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = data_one_hot.fillna(value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cleaned data from one-hot encoding the positions. \n",
    "cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Linear Regression, PCA and CCA Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is cleaned, we can explore different techniques that can be used to predict the different salaries. We will also examine how well each technique performs in salary prediction, and intuition behind each technique.\n",
    "\n",
    "First, we split the data into the set of features and the value that is being predicted, which are the salaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = cleaned.drop(axis=1, columns=['salary']), cleaned['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the easier methods used to make predictions on a model. It is a linear method that models the relationship between a variable and one or more features. A technique used in linear regression is called least squares, which finds the categorical weights that will lead to the best-fit linear regression model. The weights can be calculated for a feature matrix $X$ and a set of values $y$ using the formula $\\textbf{w} = (X^{T}X)^{-1}X^{T}y$. \n",
    "\n",
    "Fill out the cell below to implement the least squares function. There is a module in <code>sklearn</code> called <code>LinearRegression</code>, but for this part, you are not allowed to use sklearn when implementing linear regression. Additionally, you may not use <code>np.linalg.lstsq</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(features, prediction):\n",
    "    # YOUR CODE HERE #\n",
    "    # Solution #\n",
    "    return np.linalg.inv(features.T@features)@features.T@prediction\n",
    "    # End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run your <code>least_squares</code> function on the data above, and calculate the MSE for the data. Hint: use <code>np.matrix</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = least_squares(X, y)\n",
    "# Solution #\n",
    "mse_linear_reg = np.mean((y - np.matrix(X)@weights)**2) ** 0.5\n",
    "# End solution #\n",
    "mse_linear_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore some methods to see how they affect the MSE, starting with PCA below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is another method that makes use of the \"orthogonal directions\" that have the most influence on a dataset. It is useful because often times, only a few components are needed in order to make accurate predictions, as components with less weight will not have as great of an influence.\n",
    "\n",
    "To implement PCA, it it important to first scale the features, in order for certain features to not overpower other features. Additionally, we ignore class labels, making this an unsupervised learning method. Next, the mean vector is calculated using the formula $\\textbf{m} =\\frac{1}{n}\\sum_{i=1}^{n} x_i$. Next, calculate the scatter matrix, which is $S = \\sum_{i=1}^{n} (x_i - \\textbf{m})(x_i - \\textbf{m})^T$. Then find the eigenvalues and vectors of the scatter matrix, take the first num_components of the eigenvectors, and calculate the projection matrix using those eigenvectors and the scaled matrix. Finally, perform linear regression with the projection matrix.\n",
    "\n",
    "Fill out the cell below to find the MSE using PCA with linear regression for 2, 5, and 8 components. What number of components had the smallest MSE? Does increasing the number of components lower the MSE, or does it increase after a certain amount of components? Will PCA ever produce a MSE lower that that of using linear regression alone? You may only use <code>numpy</code> and not <code>PCA</code> or <code>LinearRegression</code> in this part of your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(features, preds, num_components):\n",
    "    # First, the features are scaled since no feature is more important \n",
    "    scaled = StandardScaler().fit_transform(features)\n",
    "    mean_vector = np.zeros(51)\n",
    "    \n",
    "    # YOUR CODE HERE #\n",
    "    # Solution#\n",
    "    for i in range(len(features.iloc[0, :])):\n",
    "        mean_vector[i] = np.mean(features.iloc[:, i])\n",
    "    scatter_matrix = np.zeros((51, 51))\n",
    "    for i in range(features.shape[1]):\n",
    "        scatter_matrix += (scaled[i] - mean_vector)@((scaled[i] - mean_vector).T)\n",
    "    cov_matrix = np.cov(scaled)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(scatter_matrix)\n",
    "    \n",
    "    # This line is included to account for slight complex values being included in the scatter matrix calculations\n",
    "    eigenvectors = eigenvectors.real\n",
    "    \n",
    "    proj_matrix = eigenvectors.T[0:num_components]\n",
    "    proj_data = scaled@proj_matrix.T\n",
    "    reg = LinearRegression().fit(proj_data, preds)\n",
    "    mse = np.mean((reg.predict(proj_data) - preds)**2) ** 0.5\n",
    "    return mse\n",
    "    # End Solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca(X, y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca(X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca(X, y, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the <code>PCA</code> module from <code>sklearn</code> to check your implementation of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca2 = PCA(n_components=2)\n",
    "pca2.fit(X, y)\n",
    "pca2_X = pca2.transform(X)\n",
    "reg2 = LinearRegression().fit(pca2_X, y)\n",
    "mse2 = np.mean((reg2.predict(pca2_X) - y)**2) ** 0.5\n",
    "mse2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca5 = PCA(n_components=5)\n",
    "pca5.fit(X, y)\n",
    "pca5_X = pca5.transform(X)\n",
    "reg5 = LinearRegression().fit(pca5_X, y)\n",
    "mse5 = np.mean((reg5.predict(pca5_X) - y)**2) ** 0.5\n",
    "mse5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 8 components #\n",
    "# YOUR CODE HERE#\n",
    "\n",
    "# Solution #\n",
    "pca8 = PCA(n_components=8)\n",
    "pca8.fit(X, y)\n",
    "pca8_X = pca8.transform(X)\n",
    "reg8 = LinearRegression().fit(pca8_X, y)\n",
    "mse8 = np.mean((reg8.predict(pca8_X) - y)**2) ** 0.5\n",
    "mse8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Canonical Correlation Analysis (CCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous part, we saw that PCA is an unsupervised algorithm because it does not rely on feature labels, but rather focuses on the directions with the greatest variance in the feature matrix. However, there are some situations where the most relevant dimensions are not those with the greatest variance. For example, if the feature data was contaminated with a strong, correlated noise signal, PCA would actually throw away those dimensions with this strong noise variation, the opposite of our desired outcome. In this case, we prefer to approach dimensionality reduction in a way that takes advantage of paired, i.e labeled $(X, y)$ data. This is where CCA comes into play.\n",
    "\n",
    "For this part, you will be using the <code>CCA</code> module from sklearn and create a model that is fitted to $X$ and $y$. \n",
    "\n",
    "Fill out the cells below using CCA along with linear regression to find the MSE of 2, 5, and 8 components. How does CCA perform compared to PCA with the same number of components? How does increasing the number of componetns affect the MSE? In general, CCA performs closely to linear regression. Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca2 = CCA(n_components=2)\n",
    "cca2.fit(X, y)\n",
    "cca2_X = cca2.transform(X)\n",
    "reg2 = LinearRegression().fit(cca2_X, y)\n",
    "mse2 = np.mean((reg2.predict(cca2_X) - y)**2) ** 0.5\n",
    "mse2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca5 = CCA(n_components=5)\n",
    "cca5.fit(X, y)\n",
    "cca5_X = cca5.transform(X)\n",
    "reg5 = LinearRegression().fit(cca5_X, y)\n",
    "mse5 = np.mean((reg5.predict(cca5_X) - y)**2) ** 0.5\n",
    "mse5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca8 = CCA(n_components=8)\n",
    "cca8.fit(X, y)\n",
    "cca8_X = cca5.transform(X)\n",
    "reg8 = LinearRegression().fit(cca8_X, y)\n",
    "mse8 = np.mean((reg8.predict(cca8_X) - y)**2) ** 0.5\n",
    "mse8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Noisy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous part, we saw observations from Linear Regression, PCA, and CCA on a dataset that has not been affected by noise. We will now observe what happens when our salary column has noise added to it, and how the accuracy of our predictions are affected by it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the cell below to generate noised predictions. The <code>utils.noised_predictions</code> is a black box function that will randomly add noise to our salary column using a random Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_noise = utils.noised_predictions(cleaned)\n",
    "y_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Noisy PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA with your noisy predictions and your original dataset. How does adding noise to the salary column change the MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_noise2 = PCA(n_components=2)\n",
    "pca_noise2.fit(X, y_noise)\n",
    "pca_noise2_X = pca_noise2.transform(X)\n",
    "reg_noise2 = LinearRegression().fit(pca_noise2_X, y_noise)\n",
    "mse_noise2 = np.mean((reg_noise2.predict(pca_noise2_X) - y_noise)**2) ** 0.5\n",
    "mse_noise2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_noise5 = PCA(n_components=5)\n",
    "pca_noise5.fit(X, y_noise)\n",
    "pca_noise5_X = pca_noise5.transform(X)\n",
    "reg_noise5 = LinearRegression().fit(pca_noise5_X, y_noise)\n",
    "mse_noise5 = np.mean((reg_noise5.predict(pca_noise5_X) - y_noise)**2) ** 0.5\n",
    "mse_noise5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_noise8 = PCA(n_components=8)\n",
    "pca_noise8.fit(X, y_noise)\n",
    "pca_noise8_X = pca_noise8.transform(X)\n",
    "reg_noise8 = LinearRegression().fit(pca_noise8_X, y_noise)\n",
    "mse_noise8 = np.mean((reg_noise8.predict(pca_noise8_X) - y_noise)**2) ** 0.5\n",
    "mse_noise8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Noisy CCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA with your noisy predictions and your original dataset. How does adding noise to the salary column change the MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_noise2 = CCA(n_components=2)\n",
    "cca_noise2.fit(X, y_noise)\n",
    "cca_noise2_X = cca_noise2.transform(X)\n",
    "reg_noise2 = LinearRegression().fit(cca_noise2_X, y_noise)\n",
    "mse_noise2 = np.mean((reg_noise2.predict(cca_noise2_X) - y_noise)**2) ** 0.5\n",
    "mse_noise2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_noise5 = CCA(n_components=2)\n",
    "cca_noise5.fit(X, y_noise)\n",
    "cca_noise5_X = cca_noise5.transform(X)\n",
    "reg_noise5 = LinearRegression().fit(cca_noise5_X, y_noise)\n",
    "mse_noise5 = np.mean((reg_noise5.predict(cca_noise5_X) - y_noise)**2) ** 0.5\n",
    "mse_noise5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_noise8 = CCA(n_components=2)\n",
    "cca_noise8.fit(X, y_noise)\n",
    "cca_noise8_X = cca_noise8.transform(X)\n",
    "reg_noise8 = LinearRegression().fit(cca_noise8_X, y_noise)\n",
    "mse_noise8 = np.mean((reg_noise2.predict(cca_noise8_X) - y_noise)**2) ** 0.5\n",
    "mse_noise8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Dirty Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now run the following cell in order to generate a \"dirty\" version of the above dataset. The function <code>dirty_data</code> is a black box function from the utils.py file that will alter the dataset in ways such as increasing the columns, adding strings, stringifying numbers, adding null values, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtied_data = utils.dirty_data(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Cleaning the dirty data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now need to clean this dirtied dataset. Fill out the cell below to clean the dataset so that it can be used for PCA and CCA. Hint: some useful methods can include using <code>dropna</code> and/or <code>astype</code>, fitering out rows with 0 or unknown salaries, and making sure all values are numbers, and not strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution #\n",
    "dirtied_data = dirtied_data.dropna()\n",
    "cols = dirtied_data.columns\n",
    "for i in cols:\n",
    "    dirtied_data[i] = dirtied_data[i].astype(float)\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make predictions, you will need to find the column that contains the salaries for the dirty data. Run the cell below to figure out which column name you will need to use. Then split the dirty data into a feature and prediction column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirtied_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary = 'salary' # changes every time dirty_data is run\n",
    "X_dirty = dirtied_data.drop(axis=1, columns=[salary])\n",
    "y_dirty = dirtied_data[salary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Dirty PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run PCA on your dirty dataset, using 2, 5, and 8 components and find the MSE for your predictions. How does the performance compare to PCA of the original cleaned dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_dirty2 = PCA(n_components=2)\n",
    "pca_dirty2.fit(X_dirty, y_dirty)\n",
    "pca_dirty2_X = pca_dirty2.transform(X_dirty)\n",
    "reg_dirty2 = LinearRegression().fit(pca_dirty2_X, y_dirty)\n",
    "mse_dirty2 = np.mean((reg_dirty2.predict(pca_dirty2_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_dirty5 = PCA(n_components=2)\n",
    "pca_dirty5.fit(X_dirty, y_dirty)\n",
    "pca_dirty5_X = pca_dirty5.transform(X_dirty)\n",
    "reg_dirty5 = LinearRegression().fit(pca_dirty5_X, y_dirty)\n",
    "mse_dirty5 = np.mean((reg_dirty5.predict(pca_dirty5_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_dirty8 = PCA(n_components=2)\n",
    "pca_dirty8.fit(X_dirty, y_dirty)\n",
    "pca_dirty8_X = pca_dirty8.transform(X_dirty)\n",
    "reg_dirty8 = LinearRegression().fit(pca_dirty8_X, y_dirty)\n",
    "mse_dirty8 = np.mean((reg_dirty8.predict(pca_dirty8_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Dirty CCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run CCA on your dirty dataset, using 2, 5, and 8 components and find the MSE for your predictions. How does the performance compare to CCA of the original cleaned dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_dirty2 = CCA(n_components=2)\n",
    "cca_dirty2.fit(X_dirty, y_dirty)\n",
    "cca_dirty2_X = cca_dirty2.transform(X_dirty)\n",
    "reg_dirty2 = LinearRegression().fit(cca_dirty2_X, y_dirty)\n",
    "mse_dirty2 = np.mean((reg_dirty2.predict(cca_dirty2_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_dirty5 = CCA(n_components=5)\n",
    "cca_dirty5.fit(X_dirty, y_dirty)\n",
    "cca_dirty5_X = cca_dirty5.transform(X_dirty)\n",
    "reg_dirty5 = LinearRegression().fit(cca_dirty5_X, y_dirty)\n",
    "mse_dirty5 = np.mean((reg_dirty5.predict(cca_dirty5_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_dirty8 = CCA(n_components=2)\n",
    "cca_dirty8.fit(X_dirty, y_dirty)\n",
    "cca_dirty8_X = cca_dirty8.transform(X_dirty)\n",
    "reg_dirty8 = LinearRegression().fit(cca_dirty8_X, y_dirty)\n",
    "mse_dirty8 = np.mean((reg_dirty8.predict(cca_dirty8_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
