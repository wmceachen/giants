{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project T Final: PCA and CCA\n",
    "\n",
    "By Jai Bansal, Abhinav Gopal, Grace Kull, William McEachen, Shrey Vasavada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Grace/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below only once per session. The utils.py file contains some black box functions which will be used later in this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: utils.py: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!ln -s ./utils.py utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will be looking at a real dataset of baseball players, using their game statistics to predict their salaries. Some of the information in this dataset about the players includes their names, ids, positions, years played, and their batting statistics. \n",
    "\n",
    "First, load the csv file to see all the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv(\"baseball_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>yearid</th>\n",
       "      <th>teamid</th>\n",
       "      <th>lgid</th>\n",
       "      <th>namefirst</th>\n",
       "      <th>namelast</th>\n",
       "      <th>salary</th>\n",
       "      <th>pos</th>\n",
       "      <th>g.x</th>\n",
       "      <th>gs</th>\n",
       "      <th>...</th>\n",
       "      <th>sh</th>\n",
       "      <th>sf</th>\n",
       "      <th>gidp</th>\n",
       "      <th>years</th>\n",
       "      <th>cab</th>\n",
       "      <th>ch</th>\n",
       "      <th>chr</th>\n",
       "      <th>cr</th>\n",
       "      <th>crbi</th>\n",
       "      <th>cbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abreubo01</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>LAA</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bobby</td>\n",
       "      <td>Abreu</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>OF</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>8347</td>\n",
       "      <td>2437</td>\n",
       "      <td>287</td>\n",
       "      <td>1441</td>\n",
       "      <td>1349</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abreuto01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>437</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ackledu01</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>AL</td>\n",
       "      <td>Dustin</td>\n",
       "      <td>Ackley</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>153</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>940</td>\n",
       "      <td>228</td>\n",
       "      <td>18</td>\n",
       "      <td>123</td>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adamsma01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1B</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allenbr01</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>OAK</td>\n",
       "      <td>AL</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>Allen</td>\n",
       "      <td>482500.0</td>\n",
       "      <td>O1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>344</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  yearid teamid lgid namefirst namelast     salary pos  g.x   gs  \\\n",
       "0  abreubo01  2012.0    LAA   AL     Bobby    Abreu  9000000.0  OF   54   50   \n",
       "1  abreuto01     NaN    NaN  NaN       NaN      NaN        NaN  23   21   17   \n",
       "2  ackledu01  2012.0    SEA   AL    Dustin   Ackley  2100000.0  12  153  147   \n",
       "3  adamsma01     NaN    NaN  NaN       NaN      NaN        NaN  1B   24   23   \n",
       "4  allenbr01  2012.0    OAK   AL   Brandon    Allen   482500.0  O1    6    5   \n",
       "\n",
       "   ...  sh  sf  gidp  years   cab    ch  chr    cr  crbi   cbb  \n",
       "0  ...   0   1     7     17  8347  2437  287  1441  1349  1456  \n",
       "1  ...   0   1     1      4   437   110    4    40    46    16  \n",
       "2  ...   1   1     3      2   940   228   18   123    86    99  \n",
       "3  ...   0   0     3      1    86    21    2     8    13     5  \n",
       "4  ...   0   0     0      4   344    70   12    44    41    42  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the initial obsevation of the data, it is clear that the types of data needed to predict salaries will be numerical or categorical. Additionally, rows with no salary information will have no use to us. So we'll start the data cleaning process by dropping columns that don't have categorical or numerical data, and dropping rows with no salary information. The columns being dropped are 'id', 'teamid', 'yearid', 'lgid','namefirst','namelast', and 'g_batting'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = baseball.drop(columns = ['id', 'teamid', 'yearid','lgid','namefirst','namelast', 'g_batting'])\n",
    "data = data[data['salary'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now start one-hot encoding our position data. Because there are several different positions, where each one can have an impact on a player's salary, it is important for us to take that data into account, even though it's not numerical. We will create a new column for each different kind of position and for each row, the value of that column will be 1 if the player is in that position, and 0 if the player is not. Fill out the cell below to implement one-hot encoding. Remember to drop the original 'pos' column from the dataset when the one-hot encoding is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for each of the different positions\n",
    "#Pandas Solution\n",
    "# data_one_hot = data.merge(\n",
    "#     pd.get_dummies(data['pos']),\n",
    "#      how='inner', right_index=True, left_index = True\n",
    "#     ).T.drop_duplicates().T.rename(lambda c: str(c).rsplit('_x', 1)[0], axis='columns').drop('pos', axis=1)\n",
    "\n",
    "# Solution #\n",
    "positions = np.unique(data['pos'])\n",
    "temp_array = np.array(data['pos'])\n",
    "for position in positions:\n",
    "    indicator = np.zeros(len(data['pos']))\n",
    "    for j in range(len(temp_array)):\n",
    "        if temp_array[j] == position:\n",
    "            indicator[j] = 1\n",
    "    data[position] = indicator\n",
    "# End solution #\n",
    "\n",
    "data_one_hot = data.drop(columns = ['pos'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, replace all NaN values with their column mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution\n",
    "cleaned = data_one_hot.fillna(data_one_hot.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>g.x</th>\n",
       "      <th>gs</th>\n",
       "      <th>innouts</th>\n",
       "      <th>po</th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>dp</th>\n",
       "      <th>g.y</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>C1</th>\n",
       "      <th>CF</th>\n",
       "      <th>LF</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>O3</th>\n",
       "      <th>OC</th>\n",
       "      <th>OF</th>\n",
       "      <th>RF</th>\n",
       "      <th>SS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000000.0</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>1133</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2100000.0</td>\n",
       "      <td>153</td>\n",
       "      <td>147</td>\n",
       "      <td>3953</td>\n",
       "      <td>289</td>\n",
       "      <td>398</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>153</td>\n",
       "      <td>607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>482500.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1400000.0</td>\n",
       "      <td>149</td>\n",
       "      <td>144</td>\n",
       "      <td>3829</td>\n",
       "      <td>1269</td>\n",
       "      <td>96</td>\n",
       "      <td>12</td>\n",
       "      <td>77</td>\n",
       "      <td>155</td>\n",
       "      <td>549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>483000.0</td>\n",
       "      <td>147</td>\n",
       "      <td>142</td>\n",
       "      <td>3680</td>\n",
       "      <td>257</td>\n",
       "      <td>410</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "      <td>147</td>\n",
       "      <td>576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2200000.0</td>\n",
       "      <td>145</td>\n",
       "      <td>143</td>\n",
       "      <td>3819</td>\n",
       "      <td>73</td>\n",
       "      <td>264</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>149</td>\n",
       "      <td>525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>481000.0</td>\n",
       "      <td>107</td>\n",
       "      <td>64</td>\n",
       "      <td>1783</td>\n",
       "      <td>120</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>106</td>\n",
       "      <td>275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1300000.0</td>\n",
       "      <td>127</td>\n",
       "      <td>107</td>\n",
       "      <td>3036</td>\n",
       "      <td>195</td>\n",
       "      <td>306</td>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>127</td>\n",
       "      <td>384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2625000.0</td>\n",
       "      <td>153</td>\n",
       "      <td>150</td>\n",
       "      <td>3999</td>\n",
       "      <td>233</td>\n",
       "      <td>414</td>\n",
       "      <td>16</td>\n",
       "      <td>91</td>\n",
       "      <td>158</td>\n",
       "      <td>629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1250000.0</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>1146</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       salary  g.x   gs  innouts    po    a   e  dp  g.y   ab  ...   C1   CF  \\\n",
       "0   9000000.0   54   50     1133    70    2   1   1  100  219  ...  0.0  0.0   \n",
       "2   2100000.0  153  147     3953   289  398   8  96  153  607  ...  0.0  0.0   \n",
       "4    482500.0    6    5      129    29    2   0   1   10   20  ...  0.0  0.0   \n",
       "5   1400000.0  149  144     3829  1269   96  12  77  155  549  ...  0.0  0.0   \n",
       "6    483000.0  147  142     3680   257  410  11  83  147  576  ...  0.0  0.0   \n",
       "7   2200000.0  145  143     3819    73  264  27  23  149  525  ...  0.0  0.0   \n",
       "8    481000.0  107   64     1783   120  128   4  22  106  275  ...  0.0  0.0   \n",
       "11  1300000.0  127  107     3036   195  306  13  71  127  384  ...  0.0  0.0   \n",
       "12  2625000.0  153  150     3999   233  414  16  91  158  629  ...  0.0  0.0   \n",
       "13  1250000.0   62   37     1146   115    2   2   0   68  158  ...  0.0  1.0   \n",
       "\n",
       "     LF   O1   O2   O3   OC   OF   RF   SS  \n",
       "0   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
       "13  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 52 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaned data from one-hot encoding the positions. \n",
    "cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Linear Regression, PCA and CCA Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is cleaned, we can explore different techniques that can be used to predict the different salaries. We will also examine how well each technique performs in salary prediction, and intuition behind each technique.\n",
    "\n",
    "First, we split the data into the set of features and the value that is being predicted, which are the salaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = cleaned.drop(columns=['salary'], axis=1), cleaned['salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the easiest methods to make a predictive model. \\\n",
    "It is a linear method that models the relationship between one or more features (independent variables)\n",
    "and an outcome variable (dependent variable). Least squares is a common method within linear regression \n",
    "that finds the feature weights that will lead to the best-fit linear regression model. The formula for\n",
    "Least Squares is $y = \\mathbf{X}w$, where $y$ is our outcome, $\\mathbf{X}$ is our set of features, and \n",
    "$w$ is the weight for each feature. The weights can be calculated using the formula \n",
    "$\\textbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}y$. \n",
    "\n",
    "Fill out the cell below to implement the least squares function. You may not use sklearn or NumPy's \n",
    "built-in function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(features, prediction):\n",
    "    # YOUR CODE HERE #\n",
    "    # Solution #\n",
    "    return np.linalg.inv(features.T @ features) @ features.T @ prediction\n",
    "    # End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run your <code>least_squares</code> function on the data above, and calculate the MSE for the data. Hint: use <code>np.matrix</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2699272.5784772914"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = least_squares(X, y)\n",
    "# Solution #\n",
    "mse_linear_reg = np.mean((y - np.matrix(X)@weights)**2) ** 0.5\n",
    "# End solution #\n",
    "mse_linear_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore some methods to see how they affect the MSE, starting with PCA below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, fill out the following cell to plot the singular values of the cleaned dataset. Hint: <code>np.linalg.eig</code> might be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Magnitude')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution #\n",
    "singular_values, vectors = np.linalg.eig(cleaned.T@cleaned)\n",
    "x_labels = range(len(singular_values))\n",
    "# End solution #\n",
    "# The y axis is on a log scale to better see the difference in sizes between the eigenvalues\n",
    "plt.figure(figsize=[10, 6])\n",
    "plt.yscale(\"log\")\n",
    "plt.scatter(x_labels, singular_values)\n",
    "plt.title(\"Singular values of the cleaned dataset\")\n",
    "plt.xlabel(\"Singular value index\")\n",
    "plt.ylabel(\"Magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fill out the following cell to implement <code>svd_manual</code>. You may not use <code>np.linalg.svd</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that returns the matrix with singular values on the diagonal and zeros elsewhere\n",
    "def get_diag(rows, cols, values):\n",
    "    mat = np.zeros((rows, cols))\n",
    "    index = 0\n",
    "    for i in values:\n",
    "        mat[index][index] = i\n",
    "        index += 1\n",
    "    return mat\n",
    "\n",
    "# Computes the SVD of matrix X\n",
    "def svd_manual(X):\n",
    "    # Solution #\n",
    "    X_trans_X = X.T@X\n",
    "    X_X_trans = X@X.T\n",
    "    V = np.linalg.eig(X_X_trans)[1]\n",
    "    singular_values, U = np.linalg.eig(X_trans_X)\n",
    "    D = get_diag(len(U), len(V), singular_values)\n",
    "    # End Solution #\n",
    "    # If the number of rows is greater than the number of columns, transpose the matrices before returning #\n",
    "    if (len(X) > len(X[0])):\n",
    "        U, D, V = V.T, D.T, U.T\n",
    "    return U, D, V\n",
    "\n",
    "u, d, v = svd_manual(np.array(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see what happens when only the first $k$ singular values are used to approximate the original matrix. As seen in the plot above, the magnitude of the singualr levels off after only a few of them. As a result, the approximation of the original matrix of only a few singular values may not be far off from an approximation using most of the singular values. In fact, when approximating a matrix A with a rank-k matrix $A_k$, the Eckartâ€“Youngâ€“Mirsky theorem states that for a matrix $A = UDV^T$ with rank r, for any integer k, where $0<=k<=r$, the best rank-k approximation of $A$ is $A_k = \\sum_{i=1}^{k} \\sigma_i u_i v_i^T$, where $u_i$ and $v_i$ denote the $i$th columns of $\\textbf{U}$ and $\\textbf{V}$, respectively. \n",
    "\n",
    "Fill out the cell below to implement <code>svd_k_approx</code>. You may use <code>np.linalg.svd</code> in your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the best rank-k approximation of X\n",
    "def svd_k_approx(X, k):\n",
    "    # if the rank of X is less than or equal to k, return X\n",
    "    if np.linalg.matrix_rank(X) <= k:\n",
    "        return X\n",
    "    else:\n",
    "        # Solution #\n",
    "        U, D, V = np.linalg.svd(X)\n",
    "        diag = get_diag(k, k, D[:k])\n",
    "        k_approx = U[:, :k]@diag@V[:k, :]\n",
    "        return k_approx\n",
    "        # End Solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run your <code>least_squares</code> function from part 2a on rank 2, 5, and 10 approximations of the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1277404403.9429624"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_2 = least_squares(svd_k_approx(X, 2), y)\n",
    "mse_rank_2 = np.mean((y - X@weights_2)**2) ** 0.5\n",
    "mse_rank_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255303511.9349768"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_5 = least_squares(svd_k_approx(X, 5), y)\n",
    "mse_rank_5 = np.mean((y - X@weights_5)**2) ** 0.5\n",
    "mse_rank_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1287023377.4337676"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_10 = least_squares(svd_k_approx(X, 10), y)\n",
    "mse_rank_10 = np.mean((y - X@weights_10)**2) ** 0.5\n",
    "mse_rank_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to the MSE as the rank increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a method that makes use of the \"orthogonal directions\" that have the most influence on a dataset. It is useful because often only a few components are needed in order to make accurate predictions while components with less weight are barely influential.\n",
    "\n",
    "To implement PCA, it it important to first scale the features, in order for certain features to not overpower other features. Next, the mean vector is calculated using the formula $\\textbf{m} =\\frac{1}{n}\\sum_{i=1}^{n} x_i$. Next, calculate the scatter matrix, which is $S = \\sum_{i=1}^{n} (x_i - \\textbf{m})(x_i - \\textbf{m})^T$. Then find the eigenvalues and vectors of the scatter matrix, take the first num_components of the eigenvectors, and calculate the projection matrix using those eigenvectors and the scaled matrix. Finally, perform linear regression with the projection matrix.\n",
    "\n",
    "Fill out the cell below to calculate the MSE for linear regresion with `num_components` features. You may only use <code>numpy</code> and not <code>PCA</code> or <code>LinearRegression</code> in this part of your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(features, preds, num_components):\n",
    "    # First, the features are scaled since no feature is more important \n",
    "    scaled = StandardScaler().fit_transform(features)\n",
    "    mean_vector = np.zeros(51)\n",
    "    \n",
    "    # YOUR CODE HERE #\n",
    "    # Solution#\n",
    "    for i in range(len(features.iloc[0, :])):\n",
    "        mean_vector[i] = np.mean(features.iloc[:, i])\n",
    "    scatter_matrix = np.zeros((51, 51))\n",
    "    for i in range(features.shape[1]):\n",
    "        scatter_matrix += (scaled[i] - mean_vector)@((scaled[i] - mean_vector).T)\n",
    "    cov_matrix = np.cov(scaled)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(scatter_matrix)\n",
    "    \n",
    "    # This line is included to account for slight complex values being included in the scatter matrix calculations\n",
    "    eigenvectors = eigenvectors.real\n",
    "    \n",
    "    proj_matrix = eigenvectors.T[0:num_components]\n",
    "    proj_data = scaled@proj_matrix.T\n",
    "    reg = LinearRegression().fit(proj_data, preds)\n",
    "    mse = np.mean((reg.predict(proj_data) - preds)**2) ** 0.5\n",
    "    return mse\n",
    "    # End Solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the following cells below to find the MSE using PCA with linear regression for 2, 5, and 8 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3654226.6699677957"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca(X, y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3610108.431577425"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca(X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3587433.017884171"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca(X, y, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What number of components had the smallest MSE? Does increasing the number of components lower the MSE, or does it increase after a certain amount of components? Will PCA ever produce a MSE lower that that of using linear regression alone?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the <code>PCA</code> and `LinearRegression()` modules from <code>sklearn</code> to check your implementation of PCA. First, we'll write a function to calculate MSE from an OLS model with `num_components` number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_PCA(features, preds, num_components):\n",
    "    # SOLUTION\n",
    "    pca = PCA(n_components=num_components)\n",
    "    pca.fit(features, preds)\n",
    "    pca_X = pca.transform(features)\n",
    "    reg = LinearRegression().fit(pca_X, preds)\n",
    "    return np.mean((reg.predict(pca_X) - preds)**2) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following 3 cells, run this function with 2, 5, and 8 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3504538.537484557"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_PCA(X, y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3339477.135289231"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_PCA(X, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3095173.409120575"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_PCA(X, y, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to graph the number of components, versus the MSE, for PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of PCA components vs. MSE')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_plot = [i for i in range(1, X.shape[1])]\n",
    "Y_plot = []\n",
    "for i in X_plot:\n",
    "    pca_i = PCA(n_components=i)\n",
    "    pca_i.fit(X, y)\n",
    "    pca_i_X = pca_i.transform(X)\n",
    "    reg_i = LinearRegression().fit(pca_i_X, y)\n",
    "    Y_plot.append(np.mean((reg_i.predict(pca_i_X) - y)**2) ** 0.5)\n",
    "plt.plot(X_plot, Y_plot)\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Number of PCA components vs. MSE\")\n",
    "    \n",
    "# interact(plot, n_components=IntSlider(min=0, max=X.shape[1], continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Canonical Correlation Analysis (CCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous part, we saw that PCA is an unsupervised algorithm because it does not rely on feature labels, but rather focuses on the directions with the greatest variance in the feature matrix. However, there are some situations where the most relevant dimensions are not those with the greatest variance. For example, if the feature data was contaminated with a strong, correlated noise signal, PCA would actually throw away those dimensions with this strong noise variation, the opposite of our desired outcome. In this case, we prefer to approach dimensionality reduction in a way that takes advantage of paired, i.e labeled $(X, y)$ data. This is where CCA comes into play.\n",
    "\n",
    "Fill out the cells below using CCA along with linear regression to find the MSE of 2, 5, and 8 components. How does CCA perform compared to PCA with the same number of components? How does increasing the number of componetns affect the MSE? In general, CCA performs closely to linear regression. Why is that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py:323: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2699272.5784772914"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca2 = CCA(n_components=2)\n",
    "cca2.fit(X, y)\n",
    "cca2_X = cca2.transform(X)\n",
    "reg2 = LinearRegression().fit(cca2_X, y)\n",
    "mse2 = np.mean((reg2.predict(cca2_X) - y)**2) ** 0.5\n",
    "mse2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py:323: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2699272.5784772914"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca5 = CCA(n_components=5)\n",
    "cca5.fit(X, y)\n",
    "cca5_X = cca5.transform(X)\n",
    "reg5 = LinearRegression().fit(cca5_X, y)\n",
    "mse5 = np.mean((reg5.predict(cca5_X) - y)**2) ** 0.5\n",
    "mse5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py:323: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2699272.5784772914"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca8 = CCA(n_components=8)\n",
    "cca8.fit(X, y)\n",
    "cca8_X = cca5.transform(X)\n",
    "reg8 = LinearRegression().fit(cca8_X, y)\n",
    "mse8 = np.mean((reg8.predict(cca8_X) - y)**2) ** 0.5\n",
    "mse8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Noisy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous part, we saw observations from Linear Regression, PCA, and CCA on a dataset that has not been affected by noise. We will now observe what happens when our salary column has noise added to it, and how the accuracy of our predictions are affected by it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, run the cell below to generate noised predictions. The <code>utils.noised_predictions</code> is a black box function that will randomly add noise to our salary column using a random Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      8.998205e+06\n",
       "2      2.106635e+06\n",
       "4      4.744029e+05\n",
       "5      1.370400e+06\n",
       "6      4.806524e+05\n",
       "           ...     \n",
       "621    6.782441e+06\n",
       "622    5.301801e+05\n",
       "624    1.623634e+07\n",
       "625    1.199633e+07\n",
       "626    4.651153e+06\n",
       "Name: salary, Length: 421, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_noise = utils.noised_predictions(cleaned)\n",
    "y_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Noisy PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sklearn_PCA` with your noisy predictions and 2, 5, and 8 of the features from the original dataset. How does adding noise to the salary column change the MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3503556.872572767"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "sklearn_PCA(X, y_noise, 2)\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3338913.37512543"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "sklearn_PCA(X, y_noise, 5)\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3094444.62629387"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "sklearn_PCA(X, y_noise, 8)\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Noisy CCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA with your noisy predictions and your original dataset. How does adding noise to the salary column change the MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py:323: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2699452.881145035"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_noise2 = CCA(n_components=2)\n",
    "cca_noise2.fit(X, y_noise)\n",
    "cca_noise2_X = cca_noise2.transform(X)\n",
    "reg_noise2 = LinearRegression().fit(cca_noise2_X, y_noise)\n",
    "mse_noise2 = np.mean((reg_noise2.predict(cca_noise2_X) - y_noise)**2) ** 0.5\n",
    "mse_noise2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py:323: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2699452.881145035"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_noise5 = CCA(n_components=2)\n",
    "cca_noise5.fit(X, y_noise)\n",
    "cca_noise5_X = cca_noise5.transform(X)\n",
    "reg_noise5 = LinearRegression().fit(cca_noise5_X, y_noise)\n",
    "mse_noise5 = np.mean((reg_noise5.predict(cca_noise5_X) - y_noise)**2) ** 0.5\n",
    "mse_noise5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py:323: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2699452.881145035"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_noise8 = CCA(n_components=2)\n",
    "cca_noise8.fit(X, y_noise)\n",
    "cca_noise8_X = cca_noise8.transform(X)\n",
    "reg_noise8 = LinearRegression().fit(cca_noise8_X, y_noise)\n",
    "mse_noise8 = np.mean((reg_noise2.predict(cca_noise8_X) - y_noise)**2) ** 0.5\n",
    "mse_noise8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Dirty Data\n",
    "In industry contexts, you will often rely on remote data that has been collected in some black box form. This section will work through the process of uncovering this data and cleaning it. The following call creates a `hw.db` file in the same directory as this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.make_db('baseball_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Cleaning the dirty data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a SQLite DB we can access. Connect to this database and create a pandas DataFrame from the table within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "#SOLUTION\n",
    "dirty_data = pd.read_sql(\"SELECT * FROM df\", con=sqlite3.connect('hw.db'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SO</th>\n",
       "      <th>hr</th>\n",
       "      <th>'crbi'</th>\n",
       "      <th>dp</th>\n",
       "      <th>ch</th>\n",
       "      <th>sf</th>\n",
       "      <th>hbp</th>\n",
       "      <th>yearid</th>\n",
       "      <th>'cs'</th>\n",
       "      <th>...</th>\n",
       "      <th>CR</th>\n",
       "      <th>x2b</th>\n",
       "      <th>BB</th>\n",
       "      <th>GS</th>\n",
       "      <th>RBI</th>\n",
       "      <th>'sh'</th>\n",
       "      <th>g.x</th>\n",
       "      <th>lgid</th>\n",
       "      <th>namelast</th>\n",
       "      <th>'x3b'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>None</td>\n",
       "      <td>210.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bourjos</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>169.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>37</td>\n",
       "      <td>392.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>206</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481</td>\n",
       "      <td>109.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>36</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Fukudome</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>None</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Parmelee</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     SO    hr  'crbi'    dp     ch   sf   hbp  yearid  'cs'  ...  \\\n",
       "0     55   44.0   3.0    77.0  None  210.0  3.0     3  2012.0   1.0  ...   \n",
       "1    134  169.0  33.0   222.0    37  392.0  3.0     7  2012.0   3.0  ...   \n",
       "2    481  109.0  11.0    85.0    36  128.0  0.0     3     NaN   1.0  ...   \n",
       "3    195    NaN   NaN   195.0     0  498.0  2.0     0  2012.0   1.0  ...   \n",
       "4    434   52.0   5.0    34.0  None   71.0  1.0  None     NaN   0.0  ...   \n",
       "\n",
       "     CR   x2b    BB    GS   RBI  'sh'   g.x  lgid  namelast  'x3b'  \n",
       "0   118   7.0  15.0  48.0  19.0   NaN  90.0    AL   Bourjos    0.0  \n",
       "1   206  20.0  37.0  77.0  85.0   0.0  79.0    AL      None    0.0  \n",
       "2    90  14.0  30.0  65.0  42.0   3.0  90.0  None       nan    0.0  \n",
       "3  None   1.0   8.0  11.0   4.0   0.0  15.0    AL  Fukudome    0.0  \n",
       "4    26  10.0  13.0   NaN  20.0   NaN   NaN  None  Parmelee    2.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this data has several issues: there are nan values, duplicate rows, column name changes, and data format changes. Let's clean this data!\n",
    "\n",
    "First, let's standardize the column labels. (Hint: how can we create a predictable format invariant to the headers' current form?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>SO</th>\n",
       "      <th>HR</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>DP</th>\n",
       "      <th>CH</th>\n",
       "      <th>SF</th>\n",
       "      <th>HBP</th>\n",
       "      <th>YEARID</th>\n",
       "      <th>CS</th>\n",
       "      <th>...</th>\n",
       "      <th>CR</th>\n",
       "      <th>X2B</th>\n",
       "      <th>BB</th>\n",
       "      <th>GS</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SH</th>\n",
       "      <th>G.X</th>\n",
       "      <th>LGID</th>\n",
       "      <th>NAMELAST</th>\n",
       "      <th>X3B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>None</td>\n",
       "      <td>210.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bourjos</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>169.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>37</td>\n",
       "      <td>392.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>206</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481</td>\n",
       "      <td>109.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>36</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Fukudome</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>None</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Parmelee</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX     SO    HR   CRBI    DP     CH   SF   HBP  YEARID   CS  ...    CR  \\\n",
       "0     55   44.0   3.0   77.0  None  210.0  3.0     3  2012.0  1.0  ...   118   \n",
       "1    134  169.0  33.0  222.0    37  392.0  3.0     7  2012.0  3.0  ...   206   \n",
       "2    481  109.0  11.0   85.0    36  128.0  0.0     3     NaN  1.0  ...    90   \n",
       "3    195    NaN   NaN  195.0     0  498.0  2.0     0  2012.0  1.0  ...  None   \n",
       "4    434   52.0   5.0   34.0  None   71.0  1.0  None     NaN  0.0  ...    26   \n",
       "\n",
       "    X2B    BB    GS   RBI   SH   G.X  LGID  NAMELAST  X3B  \n",
       "0   7.0  15.0  48.0  19.0  NaN  90.0    AL   Bourjos  0.0  \n",
       "1  20.0  37.0  77.0  85.0  0.0  79.0    AL      None  0.0  \n",
       "2  14.0  30.0  65.0  42.0  3.0  90.0  None       nan  0.0  \n",
       "3   1.0   8.0  11.0   4.0  0.0  15.0    AL  Fukudome  0.0  \n",
       "4  10.0  13.0   NaN  20.0  NaN   NaN  None  Parmelee  2.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solution\n",
    "dirty_data = dirty_data.rename(lambda col: col.strip('\\''), axis='columns').rename(lambda col: col.upper(), axis='columns')\n",
    "dirty_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, drop duplicates. (Hint: some columns have no Nan values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>SO</th>\n",
       "      <th>HR</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>DP</th>\n",
       "      <th>CH</th>\n",
       "      <th>SF</th>\n",
       "      <th>HBP</th>\n",
       "      <th>YEARID</th>\n",
       "      <th>CS</th>\n",
       "      <th>...</th>\n",
       "      <th>CR</th>\n",
       "      <th>X2B</th>\n",
       "      <th>BB</th>\n",
       "      <th>GS</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SH</th>\n",
       "      <th>G.X</th>\n",
       "      <th>LGID</th>\n",
       "      <th>NAMELAST</th>\n",
       "      <th>X3B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>None</td>\n",
       "      <td>210.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bourjos</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134</td>\n",
       "      <td>169.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>37</td>\n",
       "      <td>392.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>206</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481</td>\n",
       "      <td>109.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>36</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>None</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>Fukudome</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>None</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Parmelee</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDEX     SO    HR   CRBI    DP     CH   SF   HBP  YEARID   CS  ...    CR  \\\n",
       "0     55   44.0   3.0   77.0  None  210.0  3.0     3  2012.0  1.0  ...   118   \n",
       "1    134  169.0  33.0  222.0    37  392.0  3.0     7  2012.0  3.0  ...   206   \n",
       "2    481  109.0  11.0   85.0    36  128.0  0.0     3     NaN  1.0  ...    90   \n",
       "3    195    NaN   NaN  195.0     0  498.0  2.0     0  2012.0  1.0  ...  None   \n",
       "4    434   52.0   5.0   34.0  None   71.0  1.0  None     NaN  0.0  ...    26   \n",
       "\n",
       "    X2B    BB    GS   RBI   SH   G.X  LGID  NAMELAST  X3B  \n",
       "0   7.0  15.0  48.0  19.0  NaN  90.0    AL   Bourjos  0.0  \n",
       "1  20.0  37.0  77.0  85.0  0.0  79.0    AL      None  0.0  \n",
       "2  14.0  30.0  65.0  42.0  3.0  90.0  None       nan  0.0  \n",
       "3   1.0   8.0  11.0   4.0  0.0  15.0    AL  Fukudome  0.0  \n",
       "4  10.0  13.0   NaN  20.0  NaN   NaN  None  Parmelee  2.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solution\n",
    "dirty_data = dirty_data.drop_duplicates(subset=['ID'])\n",
    "dirty_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NaN values with their column mean. This requires setting columns with string values back to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDEX</th>\n",
       "      <th>SO</th>\n",
       "      <th>HR</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>DP</th>\n",
       "      <th>CH</th>\n",
       "      <th>SF</th>\n",
       "      <th>HBP</th>\n",
       "      <th>YEARID</th>\n",
       "      <th>CS</th>\n",
       "      <th>...</th>\n",
       "      <th>CR</th>\n",
       "      <th>X2B</th>\n",
       "      <th>BB</th>\n",
       "      <th>GS</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SH</th>\n",
       "      <th>G.X</th>\n",
       "      <th>LGID</th>\n",
       "      <th>NAMELAST</th>\n",
       "      <th>X3B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.0</td>\n",
       "      <td>44.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>17.886288</td>\n",
       "      <td>210.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.368687</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Bourjos</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134.0</td>\n",
       "      <td>169.00000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>222.0</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>392.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481.0</td>\n",
       "      <td>109.00000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195.0</td>\n",
       "      <td>54.12116</td>\n",
       "      <td>7.867572</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>242.431779</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Fukudome</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434.0</td>\n",
       "      <td>52.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17.886288</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.388982</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63.244932</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.368687</td>\n",
       "      <td>72.123311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Parmelee</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>145.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>197.0</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>585.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>1811.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1059.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>NL</td>\n",
       "      <td>Furcal</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>368.0</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>166.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Mathis</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>342.0</td>\n",
       "      <td>46.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>111.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>NL</td>\n",
       "      <td>Lombardozzi</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>619.0</td>\n",
       "      <td>108.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>610.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>641.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>AL</td>\n",
       "      <td>Youkilis</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>628 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      INDEX         SO         HR   CRBI         DP      CH   SF        HBP  \\\n",
       "0      55.0   44.00000   3.000000   77.0  17.886288   210.0  3.0   3.000000   \n",
       "1     134.0  169.00000  33.000000  222.0  37.000000   392.0  3.0   7.000000   \n",
       "2     481.0  109.00000  11.000000   85.0  36.000000   128.0  0.0   3.000000   \n",
       "3     195.0   54.12116   7.867572  195.0   0.000000   498.0  2.0   0.000000   \n",
       "4     434.0   52.00000   5.000000   34.0  17.886288    71.0  1.0   2.388982   \n",
       "...     ...        ...        ...    ...        ...     ...  ...        ...   \n",
       "1756  145.0    5.00000   0.000000    0.0   4.000000     4.0  0.0   1.000000   \n",
       "1770  197.0   57.00000   5.000000  585.0  68.000000  1811.0  4.0   1.000000   \n",
       "1844  368.0   68.00000   8.000000  166.0   5.000000   279.0  1.0   0.000000   \n",
       "1867  342.0   46.00000   3.000000   28.0  29.000000   111.0  1.0   6.000000   \n",
       "1868  619.0  108.00000  19.000000  610.0  40.000000  1030.0  3.0  17.000000   \n",
       "\n",
       "      YEARID   CS  ...           CR   X2B    BB          GS   RBI        SH  \\\n",
       "0     2012.0  1.0  ...   118.000000   7.0  15.0   48.000000  19.0  1.368687   \n",
       "1     2012.0  3.0  ...   206.000000  20.0  37.0   77.000000  85.0  0.000000   \n",
       "2     2012.0  1.0  ...    90.000000  14.0  30.0   65.000000  42.0  3.000000   \n",
       "3     2012.0  1.0  ...   242.431779   1.0   8.0   11.000000   4.0  0.000000   \n",
       "4     2012.0  0.0  ...    26.000000  10.0  13.0   63.244932  20.0  1.368687   \n",
       "...      ...  ...  ...          ...   ...   ...         ...   ...       ...   \n",
       "1756  2012.0  0.0  ...     4.000000   0.0   1.0    4.000000   0.0  0.000000   \n",
       "1770  2012.0  4.0  ...  1059.000000  18.0  44.0  116.000000  49.0  5.000000   \n",
       "1844  2012.0  0.0  ...   157.000000  13.0   9.0   59.000000  27.0  6.000000   \n",
       "1867  2012.0  3.0  ...    43.000000  16.0  19.0   83.000000  27.0  6.000000   \n",
       "1868  2012.0  0.0  ...   641.000000  15.0  51.0  121.000000  60.0  0.000000   \n",
       "\n",
       "             G.X  LGID     NAMELAST  X3B  \n",
       "0      90.000000    AL      Bourjos  0.0  \n",
       "1      79.000000    AL          NaN  0.0  \n",
       "2      90.000000   NaN          nan  0.0  \n",
       "3      15.000000    AL     Fukudome  0.0  \n",
       "4      72.123311   NaN     Parmelee  2.0  \n",
       "...          ...   ...          ...  ...  \n",
       "1756    5.000000   NaN          nan  0.0  \n",
       "1770  120.000000    NL       Furcal  3.0  \n",
       "1844   66.000000    AL       Mathis  0.0  \n",
       "1867  106.000000    NL  Lombardozzi  3.0  \n",
       "1868  137.000000    AL     Youkilis  2.0  \n",
       "\n",
       "[628 rows x 41 columns]"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solution\n",
    "for col in dirty_data:\n",
    "        try:\n",
    "            dirty_data[col] = dirty_data[col].astype(float)\n",
    "        except:\n",
    "            pass\n",
    "dirty_data = dirty_data.fillna(np.nan)\n",
    "\n",
    "dirty_data = dirty_data.fillna(dirty_data.mean())\n",
    "dirty_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare our data, one-hot-encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_dirty_data = dirty_data.copy()\n",
    "for col in ('POS', 'TEAMID', 'LGID'):\n",
    "    ohe_dirty_data = ohe_dirty_data.merge(\n",
    "    pd.get_dummies(dirty_data[col]),\n",
    "     how='inner', right_index=True, left_index = True\n",
    "    ).T.drop_duplicates().T.rename(lambda c: str(c).rsplit('_x', 1)[0], axis='columns').drop(col, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need player names/ID, so remove those features (they aren't useful categorical features). Additionally, drop the 'INDEX' column because it is a residual from importing SQL data. Because `G_BATTING` is all nan, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "ohe_dirty_data = ohe_dirty_data.drop(['INDEX', 'ID', 'NAMEFIRST', 'NAMELAST', 'G_BATTING'], axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G_BATTING    628\n",
       "dtype: int64"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_dirty_data.isna().sum()[ohe_dirty_data.isna().sum().astype(bool)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data clean, let's split our data into our features and prediction column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dirty = ohe_dirty_data.drop(columns=['SALARY'])\n",
    "y_dirty = ohe_dirty_data['SALARY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Dirty PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run PCA on your dirty dataset, using 2, 5, and 8 components and find the MSE for your predictions. How does the performance compare to PCA of the original cleaned dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-437-2b397cd80ed1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Solution #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca_dirty2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpca_dirty2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dirty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dirty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpca_dirty2_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_dirty2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dirty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mreg_dirty2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_dirty2_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dirty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \"\"\"\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0m\u001b[1;32m    398\u001b[0m                                 ensure_2d=True, copy=self.copy)\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/personal/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# PCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_dirty2 = PCA(n_components=2)\n",
    "pca_dirty2.fit(X_dirty, y_dirty)\n",
    "pca_dirty2_X = pca_dirty2.transform(X_dirty)\n",
    "reg_dirty2 = LinearRegression().fit(pca_dirty2_X, y_dirty)\n",
    "mse_dirty2 = np.mean((reg_dirty2.predict(pca_dirty2_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3651656.437507077"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_dirty5 = PCA(n_components=2)\n",
    "pca_dirty5.fit(X_dirty, y_dirty)\n",
    "pca_dirty5_X = pca_dirty5.transform(X_dirty)\n",
    "reg_dirty5 = LinearRegression().fit(pca_dirty5_X, y_dirty)\n",
    "mse_dirty5 = np.mean((reg_dirty5.predict(pca_dirty5_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3651656.437507077"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "pca_dirty8 = PCA(n_components=2)\n",
    "pca_dirty8.fit(X_dirty, y_dirty)\n",
    "pca_dirty8_X = pca_dirty8.transform(X_dirty)\n",
    "reg_dirty8 = LinearRegression().fit(pca_dirty8_X, y_dirty)\n",
    "mse_dirty8 = np.mean((reg_dirty8.predict(pca_dirty8_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Dirty CCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run CCA on your dirty dataset, using 2, 5, and 8 components and find the MSE for your predictions. How does the performance compare to CCA of the original cleaned dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinavg/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2780163.520656927"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 2 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_dirty2 = CCA(n_components=2)\n",
    "cca_dirty2.fit(X_dirty, y_dirty)\n",
    "cca_dirty2_X = cca_dirty2.transform(X_dirty)\n",
    "reg_dirty2 = LinearRegression().fit(cca_dirty2_X, y_dirty)\n",
    "mse_dirty2 = np.mean((reg_dirty2.predict(cca_dirty2_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty2\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinavg/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2780163.5206569275"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 5 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_dirty5 = CCA(n_components=5)\n",
    "cca_dirty5.fit(X_dirty, y_dirty)\n",
    "cca_dirty5_X = cca_dirty5.transform(X_dirty)\n",
    "reg_dirty5 = LinearRegression().fit(cca_dirty5_X, y_dirty)\n",
    "mse_dirty5 = np.mean((reg_dirty5.predict(cca_dirty5_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty5\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinavg/opt/anaconda3/lib/python3.7/site-packages/sklearn/cross_decomposition/pls_.py:292: UserWarning: Y residual constant at iteration 1\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2780163.520656927"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CCA with 8 components #\n",
    "# YOUR CODE HERE #\n",
    "\n",
    "# Solution #\n",
    "cca_dirty8 = CCA(n_components=2)\n",
    "cca_dirty8.fit(X_dirty, y_dirty)\n",
    "cca_dirty8_X = cca_dirty8.transform(X_dirty)\n",
    "reg_dirty8 = LinearRegression().fit(cca_dirty8_X, y_dirty)\n",
    "mse_dirty8 = np.mean((reg_dirty8.predict(cca_dirty8_X) - y_dirty)**2) ** 0.5\n",
    "mse_dirty8\n",
    "# End solution #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill out the cell below with your observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill out this cell with observations #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
